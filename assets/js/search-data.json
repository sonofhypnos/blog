{
  
    
        "post0": {
            "title": "Title",
            "content": "new_list = [&quot;hello&quot;, &quot;its&quot;, &quot;me&quot;] counts= [1,3,4] contents = [] for i in range(len(counts)): contents += [new_list[i]] * counts[i] contents . [&#39;hello&#39;, &#39;its&#39;, &#39;its&#39;, &#39;its&#39;, &#39;me&#39;, &#39;me&#39;, &#39;me&#39;, &#39;me&#39;] .",
            "url": "https://sonofhypnos.github.io/blog/2021/02/09/Untitled.html",
            "relUrl": "/2021/02/09/Untitled.html",
            "date": " • Feb 9, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Will the SP-500 fall to index X by date Y?",
            "content": "I occasionally make predictions on the forecasting Site Almanis. Some monthly recurring questions there are of the format: &quot;By date_X, will the S&amp;P 500 fall below Index_Y?&quot; . To get a baseline for my predictions on those questions, I made this notebook. Feel free to download it for your own predictions. Here is a link to the S&amp;P 500 CSV-file which I originally downloaded from Yahoo Finance. . For this example, I will ask the question: &quot;Will the S&amp;P 500 go above 3800 by March 1st, 2021?&quot; . I assumed the SP 500 to be a (biased) random walk. This might not be true, but if I could do any better I wouldn&#39;t be betting &quot;play-money&quot; on Almanis, I would be making a fortune on Wallstreet instead. . So to answer the question of whether the S&amp;P 500 will exceed a certain index, I looked at the difference between the current index (3,714.7) and the index that we want to know the probability of exceedance for (3800). I computed this probability by looking at the frequency at which the index has moved by that much in the past1. . import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns import statsmodels.graphics as stg #we are going to use this later on to check our timeseries for autocorrelation import statsmodels.api as sm %matplotlib inline df = pd.read_csv(&quot;https://raw.githubusercontent.com/sonofhypnos/projects/master/_notebooks/%5EGSPC.csv&quot;) . days_ahead = 30 # the number of days that the S&amp;P has to stay within the boundary boundary = 3800 . So before we can answer our initial question, we need to take a look at our data. . df.head() . Date Open High Low Close Adj Close Volume . 0 1927-12-30 | 17.660000 | 17.660000 | 17.660000 | 17.660000 | 17.660000 | 0 | . 1 1928-01-03 | 17.760000 | 17.760000 | 17.760000 | 17.760000 | 17.760000 | 0 | . 2 1928-01-04 | 17.719999 | 17.719999 | 17.719999 | 17.719999 | 17.719999 | 0 | . 3 1928-01-05 | 17.549999 | 17.549999 | 17.549999 | 17.549999 | 17.549999 | 0 | . 4 1928-01-06 | 17.660000 | 17.660000 | 17.660000 | 17.660000 | 17.660000 | 0 | . As you can see this dataset goes back until 1927. Another thing to notice here is that we only have data for the S&amp;P 500 on business days. Since this is only supposed to be a rough forecast, I am going to ignore this fact and just pretend that the difference between Fridays and Mondays will be the same as between Tuesdays and Wednesdays. But we will still have to keep this fact in mind, so that our forecast also only includes workdays. . sp = df.Close sp.index = pd.to_datetime(df.Date) . sp.head() . Date 1927-12-30 17.660000 1928-01-03 17.760000 1928-01-04 17.719999 1928-01-05 17.549999 1928-01-06 17.660000 Name: Close, dtype: float64 . Let&#39;s take a first look at our timeseries . sns.lineplot(x=sp.index, y=sp.values); . As you can see the graph is growing exponentially. This is even more clear on a log scale: . sns.lineplot(x=sp.index, y=sp.values) plt.yscale(&quot;log&quot;) . We now take a closer look at the correlation in our graph. If this was a random, then there shouldn&#39;t be any correlation between price changes and this is indeed what we see: . sp_shifted = sp - sp.shift() . stg.tsaplots.plot_acf(sp_shifted[1:]) plt.show() . The following function computes the relative difference between different days in the past. . def relative_shift_n(ts, n): ts_shift = [] for i in range(1,n+1): ts_shift.append((ts - ts.shift(periods=i))/ts) return ts_shift . Now we compute the number of workdays ahead for our forecast . current_weekday = sp[-1:].index.weekday[0] + 1 days_ahead = 15 n = 0 for i in range(days_ahead): if (current_weekday % 7) &lt; 5: n += 1 current_weekday += 1 print(&quot;workdays ahead:&quot;, n) . workdays ahead: 10 . sp_shift = relative_shift_n(sp, n) shift_index = [str(x) for x in range(1,n+1)] sp_shift = pd.DataFrame.from_dict(dict(zip(shift_index,sp_shift))) sp_shift = sp_shift[n:] #removing NaN entries . sp_shift is an array of price-changes for different intervalls. The title of each column corresponds to the number of days between which the price change was computed. . sp_shift . 1 2 3 4 5 6 7 8 9 10 . Date . 1928-01-16 -0.016773 | -0.010411 | -0.003470 | -0.004627 | -0.012146 | -0.021400 | -0.015037 | -0.024870 | -0.027183 | -0.021400 | . 1928-01-17 0.000578 | -0.016185 | -0.009827 | -0.002890 | -0.004046 | -0.011561 | -0.020809 | -0.014451 | -0.024277 | -0.026590 | . 1928-01-18 -0.002317 | -0.001738 | -0.018540 | -0.012167 | -0.005214 | -0.006373 | -0.013905 | -0.023175 | -0.016802 | -0.026651 | . 1928-01-19 0.006904 | 0.004603 | 0.005178 | -0.011508 | -0.005178 | 0.001726 | 0.000575 | -0.006905 | -0.016111 | -0.009781 | . 1928-01-20 0.005721 | 0.012586 | 0.010298 | 0.010870 | -0.005721 | 0.000572 | 0.007437 | 0.006293 | -0.001144 | -0.010297 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 2021-01-04 -0.014976 | -0.008482 | -0.007131 | -0.009379 | -0.000651 | 0.002875 | 0.003618 | 0.001548 | -0.002367 | -0.005899 | . 2021-01-05 0.007033 | -0.007838 | -0.001390 | -0.000048 | -0.002281 | 0.006386 | 0.009888 | 0.010626 | 0.008570 | 0.004682 | . 2021-01-06 0.005677 | 0.012670 | -0.002116 | 0.004295 | 0.005629 | 0.003410 | 0.012027 | 0.015509 | 0.016243 | 0.014199 | . 2021-01-07 0.014630 | 0.020225 | 0.027115 | 0.012545 | 0.018863 | 0.020177 | 0.017990 | 0.026481 | 0.029912 | 0.030635 | . 2021-01-08 0.005462 | 0.020012 | 0.025576 | 0.032429 | 0.017939 | 0.024222 | 0.025529 | 0.023354 | 0.031799 | 0.035211 | . 23357 rows × 10 columns . The following function finally answers my initial question: . sp_forecast = float(sp[-1:]) + sp_shift * float(sp[-1:]) beyond_boundary = [] #change beyond boundary list based on whether our boundry is #above or below the current index of the S&amp;P 500 if float(sp[-1:]) &lt; boundary: print(&quot;probability of going above boundary:&quot;) for i in range(len(sp_forecast)): beyond_boundary.append(any(sp_forecast.iloc[i] &gt; boundary)) else: print(&quot;probability of going below boundary:&quot;) for i in range(len(sp_forecast)): beyond_boundary.append(any(sp_forecast.iloc[i] &lt; boundary)) beyond_boundary = pd.Series(beyond_boundary) print(beyond_boundary.mean()) beyond_boundary.rolling(window=365).mean().plot() axes = plt.gca() axes.set_ylim([0,1]) plt.show() . probability of going below boundary: 0.563642591086184 . As we can see the there is some variation, but the probability stays in the 40-80% range most of the time. So if the current forecast at almanis would be at 35% we could place a relatively confident bet on &quot;YES&quot;. . 1. To be precise, I computed the size of the gap between the current index and the boundary index (3900) as a percentage of the absolute index. I then looked at how often such a big gap had been exceeded in the past in the same number of days.↩ .",
            "url": "https://sonofhypnos.github.io/blog/prediction/python/2020/01/30/sp500.html",
            "relUrl": "/prediction/python/2020/01/30/sp500.html",
            "date": " • Jan 30, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Will the SP-500 fall to index X by date Y",
            "content": "So I occasionally try to make predictions on the forecasting Site Almanis and some of their questions that reocurr every month are of the format: By X (DATE), will the S&amp;P 500 fall below Index? (give concrete instead of general example?) . This notebook gives an answer to the question: What is the probability that the S&amp;P 500 will exceed the index X within the next n days? . For example what is the probability that the Of course this probability can&#39;t be taken to be exact. To be precise, I looked at how . This was useful for betting on questions on the betting Platform Almanis. Since the site asks those questions every month, I started to do this little analysis. . First of all: I do not provide any financial advice here. This is just a short blogpost about a forecast I made recently . So I occasionally try to make predictions on the forecasting Site Almanis. Some monthly recurring questions there are of the format: By date_X, will the S&amp;P 500 fall below Index_Y? . To get a baseline for my predictions I made this notebook. The main reason why I publish this on my blog now, is that I want to get better at documenting and explaining it to others. . So let&#39;s get started! To make this example more concrete we will ask the question: &quot;Will the S&amp;P 500 go above 3900 by febuary 12th 2021?&quot; . When you want to make predictions, it is a good idea to look for how often something has occured in the past. When it comes to an index like the S&amp;P 500 it makes sense to make some kind of statistical model to inform your forecast, because this will outperform any any forecast you are able to make with your intuition (here is a link to some sources I highly reccomend, if you want to learn more about forecasting). . So first a bit about markets: If you are a layperson like me, you should not expect to find any investing strategy to reliably earn money from the market through active investing. There are some caveates to this, but this is not what I am here to explain, so I&#39;ll just give you an example of what I mean: You should not believe any model you make that predicts that the S&amp;P will go up or down tomorrow with a probability of 90% (which is enough confidence to make money by buing and selling the index fund). You should be pretty &quot;humble&quot; in this case because there are bunch of firms employing people smarter and more knowlegdable about finance than you that are rewarded with any exploitable strategy they can find with a heap of money. This property is what people mean when they say a market is efficient. This is why we will assume for this model that the S&amp;P 500 is a random walk, which means that daily pricechanges are independent of each other (Because any dependency in the price would be &quot;Free money&quot; that no one bothered to pick up which is unlikely&quot;). This is not entirely true. But is good enough for the rough model we are aiming for here. Because changes in a random walk are independent of each other means that the only information that we have about the future index is where the index stands right now. So when we want to answer the question whether the S&amp;P 500 will exceed a certain index, we will look at the difference between the current index (3824,7) and the index that we want to know probability of exceedance of (3900). . For example what is the probability that the Of course this probability can&#39;t be taken to be exact. To be precise, I looked at how . This was useful for betting on questions on the betting Platform Almanis. Since the site asks those questions every month, I started to do this little analysis. . So first we import some standard libraries for data analysis . If you want to look at this yourself, you can download the data here from X and here is my notebook . import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns %matplotlib inline df = pd.read_csv(&quot;^GspC.csv&quot;) . df.head() . Date Open High Low Close Adj Close Volume . 0 1927-12-30 | 17.660000 | 17.660000 | 17.660000 | 17.660000 | 17.660000 | 0 | . 1 1928-01-03 | 17.760000 | 17.760000 | 17.760000 | 17.760000 | 17.760000 | 0 | . 2 1928-01-04 | 17.719999 | 17.719999 | 17.719999 | 17.719999 | 17.719999 | 0 | . 3 1928-01-05 | 17.549999 | 17.549999 | 17.549999 | 17.549999 | 17.549999 | 0 | . 4 1928-01-06 | 17.660000 | 17.660000 | 17.660000 | 17.660000 | 17.660000 | 0 | . df.tail() . Date Open High Low Close Adj Close Volume . 23362 2021-01-04 | 3764.610107 | 3769.989990 | 3662.709961 | 3700.649902 | 3700.649902 | 5006680000 | . 23363 2021-01-05 | 3698.020020 | 3737.830078 | 3695.070068 | 3726.860107 | 3726.860107 | 4582620000 | . 23364 2021-01-06 | 3712.199951 | 3783.040039 | 3705.340088 | 3748.139893 | 3748.139893 | 6049970000 | . 23365 2021-01-07 | 3764.709961 | 3811.550049 | 3764.709961 | 3803.790039 | 3803.790039 | 5080870000 | . 23366 2021-01-08 | 3815.050049 | 3826.689941 | 3783.600098 | 3824.679932 | 3824.679932 | 4764180000 | . sp = df.Close . sp.head() . 0 17.660000 1 17.760000 2 17.719999 3 17.549999 4 17.660000 Name: Close, dtype: float64 . sns.lineplot(x=sp.index, y=sp.values) . &lt;AxesSubplot:&gt; . As you can see from . sns.lineplot(x=sp.index[-500:], y=sp.values[-500:]) . &lt;AxesSubplot:&gt; . Now we also use the index collumn from our initial dataframe. . sp.index = pd.to_datetime(df.Date) . sp.head() . Date 1927-12-30 17.660000 1928-01-03 17.760000 1928-01-04 17.719999 1928-01-05 17.549999 1928-01-06 17.660000 Name: Close, dtype: float64 . def shift_n_absolute(ts, n): ts_shift = [] for i in range(1,n+1): ts_shift.append((ts - ts.shift(periods=i))/ts) return ts_shift def shift_n_absolute(ts, n): ts_shift = [] for i in range(1,n+1): ts_shift.append((ts - ts.shift(periods=i))) return ts_shift . sns.lineplot(x=sp.index[-500:], y = sp.values[-500:]) . &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt; . n = 15 # the number of days that the S&amp;P has to stay within the boundary boundary = 3400 #sp = sp[:-1] #remove close . sp_shift = shift_n_absolute(sp, n) shift_index = [str(x) for x in range(1,n+1)] sp_shift = pd.DataFrame.from_dict(dict(zip(shift_index,sp_shift))) sp_shift = sp_shift[n:] . sp_shift . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 . Date . 1928-01-23 0.159999 | 0.260000 | 0.379999 | 0.340000 | 0.349998 | 0.059999 | 0.170000 | 0.289999 | 0.269998 | 0.139999 | -0.020001 | 0.090000 | -0.080000 | -0.120001 | -0.020001 | . 1928-01-24 0.070000 | 0.229999 | 0.330000 | 0.449999 | 0.410000 | 0.419998 | 0.129999 | 0.240000 | 0.359999 | 0.339998 | 0.209999 | 0.049999 | 0.160000 | -0.010000 | -0.050001 | . 1928-01-25 -0.189999 | -0.119999 | 0.040000 | 0.140001 | 0.260000 | 0.220001 | 0.229999 | -0.060000 | 0.050001 | 0.170000 | 0.149999 | 0.020000 | -0.140000 | -0.029999 | -0.199999 | . 1928-01-26 0.109999 | -0.080000 | -0.010000 | 0.149999 | 0.250000 | 0.369999 | 0.330000 | 0.339998 | 0.049999 | 0.160000 | 0.279999 | 0.259998 | 0.129999 | -0.030001 | 0.080000 | . 1928-01-27 0.060002 | 0.170001 | -0.019998 | 0.050002 | 0.210001 | 0.310002 | 0.430001 | 0.390002 | 0.400000 | 0.110001 | 0.220002 | 0.340001 | 0.320000 | 0.190001 | 0.030001 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 2021-01-04 -55.420166 | -31.390137 | -26.390137 | -34.710205 | -2.410157 | 10.639892 | 13.389892 | 5.729980 | -8.760010 | -21.830078 | -0.520020 | 6.029785 | 53.159912 | 37.189941 | 32.549804 | . 2021-01-05 26.210205 | -29.209961 | -5.179932 | -0.179932 | -8.500000 | 23.800048 | 36.850097 | 39.600097 | 31.940185 | 17.450195 | 4.380127 | 25.690185 | 32.239990 | 79.370117 | 63.400146 | . 2021-01-06 21.279786 | 47.489991 | -7.930175 | 16.099854 | 21.099854 | 12.779786 | 45.079834 | 58.129883 | 60.879883 | 53.219971 | 38.729981 | 25.659913 | 46.969971 | 53.519776 | 100.649903 | . 2021-01-07 55.650146 | 76.929932 | 103.140137 | 47.719971 | 71.750000 | 76.750000 | 68.429932 | 100.729980 | 113.780029 | 116.530029 | 108.870117 | 94.380127 | 81.310059 | 102.620117 | 109.169922 | . 2021-01-08 20.889893 | 76.540039 | 97.819825 | 124.030030 | 68.609864 | 92.639893 | 97.639893 | 89.319825 | 121.619873 | 134.669922 | 137.419922 | 129.760010 | 115.270020 | 102.199952 | 123.510010 | . 23352 rows × 15 columns . sp_shift[&quot;15&quot;].rolling(window=500).mean().plot() . &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt; . sp[-5:] . Date 2021-01-04 3700.649902 2021-01-05 3726.860107 2021-01-06 3748.139893 2021-01-07 3803.790039 2021-01-08 3824.679932 Name: Close, dtype: float64 . sp_pre_forecast = float(sp[-1:]) + sp_shift * float(sp[-1:]) . # were excedet in the past #windows = 350 sp_forecast = sp_pre_forecast . float(sp[-1:]) . 3824.679932 . win = [] if float(sp[-1:]) &lt; boundary: print(&quot;probability of going above boundary&quot;) for i in range(len(sp_forecast)): win.append(any(sp_forecast.iloc[i] &gt; boundary)) else: print(&quot;probability of going below boundary&quot;) for i in range(len(sp_forecast)): win.append(any(sp_forecast.iloc[i] &lt; boundary)) win = pd.Series(win) print(win.mean()) win.rolling(window=30).mean().plot() axes = plt.gca() axes.set_ylim([0,1]) plt.show() . probability of going below boundary 0.72931654676259 .",
            "url": "https://sonofhypnos.github.io/blog/prediction/python/2020/01/10/checkpoint.html",
            "relUrl": "/prediction/python/2020/01/10/checkpoint.html",
            "date": " • Jan 10, 2020"
        }
        
    
  

  
  

  

  
      ,"page2": {
          "title": "Now",
          "content": "Right now, I’m living in Karlsruhe in Germany. I spend my time: . listening to the ClearerThinking Podcast | reading “A Journal of the Plague Year” | meeting in the AI reading group every thursday 19:45 UTC | lurking on lesswrong | studying for my university courses | .",
          "url": "https://sonofhypnos.github.io/blog/now/",
          "relUrl": "/now/",
          "date": ""
      }
      
  

  
  

  
  

  
  

  
  

  
  

  
      ,"page8": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://sonofhypnos.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}